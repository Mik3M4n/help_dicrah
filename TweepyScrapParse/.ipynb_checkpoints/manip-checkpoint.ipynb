{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Collomb a essayé de dissimuler que le terroriste de l’opéra était musulman et fiché S en annonçant qu’il était russe. #collombdemission #foutagedegueule\n",
      "Ce connard \"Collomb \"avec la complicité des traitre LERM et leur patron le président Macron préfèrent protéger les… https://t.co/OZoXvJqftQ\n",
      "Ce connard \"Collomb \"avec la complicité des traitre LERM et leur patron le président Macron préfèrent protéger les islamistes plutôt que la population qui n'à même pas le pouvoir de se défendre sans étre déféré en justice pour acte raciste . https://t.co/hjHSCZLTEz\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = 'Streams/'\n",
    "file = 'stream_racism.jsonl'\n",
    "\n",
    "df = pd.read_json(path+file, lines=True)\n",
    "#df_tweets.info()\n",
    "\n",
    "tweets = pd.DataFrame(df[[\"extended_tweet\", \"retweeted_status\"]])\n",
    "\n",
    "print(tweets.retweeted_status[1][\"quoted_status\"][\"extended_tweet\"][\"full_text\"])\n",
    "\n",
    "print(tweets.retweeted_status[1][\"text\"])\n",
    "print(tweets.retweeted_status[1][\"extended_tweet\"][\"full_text\"])\n",
    "\n",
    "# Extraction des index des lignes non vides et à parser\n",
    "index_ext = tweets.extended_tweet[tweets.extended_tweet.notnull()].index\n",
    "index_ret = tweets.retweeted_status[tweets.retweeted_status.notnull()].index\n",
    "\n",
    "# On remplace les tweets originaux et trunqués par le texte en entier\n",
    "for i in index_ext:\n",
    "    tweets[\"extended_tweet\"][i] = tweets.extended_tweet[i][\"full_text\"]\n",
    "\n",
    "# Pour les messages retweetés (reteewted_status) on a streamé un dict à plusiers niveaux\n",
    "# Chaque json a une structure différente. Nous voulons récupérer deux champs:\n",
    "# 1. les messages retweetés en entier et 2. les messages cités par le même usager\n",
    "\n",
    "# 1. Si le stream a un champ \"extended_tweet\" on récupère les index des ces tweets\n",
    "# pour effectuer ensuite une boucle d'extraction du texte en entier.\n",
    "# Sinon (else), le message n'a pas été trunqué, on utilise le champ entier \"text\"\n",
    "j=[]\n",
    "for i in index_ret:\n",
    "    if \"extended_tweet\" in tweets.retweeted_status[i]:\n",
    "        j.append(i)\n",
    "    else:\n",
    "        tweets.retweeted_status[i] = tweets.retweeted_status[i][\"text\"]\n",
    "\n",
    "for i in j:\n",
    "    tweets.retweeted_status[i] = tweets.retweeted_status[i][\"extended_tweet\"][\"full_text\"]\n",
    "\n",
    "# 2. Sur la même colonne d'avant on trouve le texte des messages cités par l'usager.  \n",
    "# Pour ne pas l'écraser, on crée une nouvelle colonne ou l'on placera le texte en entier\n",
    "k=[]\n",
    "for i in index_ret:\n",
    "    if \"quoted_status\" in df.retweeted_status[i]:\n",
    "        k.append(i)\n",
    "    else:\n",
    "        tweets[\"cite_status\"] = None\n",
    "\n",
    "for i in k:\n",
    "    tweets.cite_status[i] = df.retweeted_status[i][\"quoted_status\"][\"extended_tweet\"][\"full_text\"]\n",
    "\n",
    "tweets_dilcrah = tweets.stack().dropna().reset_index(drop=True)\n",
    "\n",
    "tweets_dilcrah.to_csv('tweets_dilcrah.csv', sep=',', encoding='utf-8', header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-04f9c50552fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mext_tw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended_tweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended_tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#ext_rtw = df_tweets[pd.notna(df_tweets.reteewted_status)].retweeted_status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_tweets' is not defined"
     ]
    }
   ],
   "source": [
    "#testing = df_tweets.text\n",
    "#testing.to_csv('tweets_original.csv', sep=',', encoding='utf-8', header = False)\n",
    "\n",
    "\n",
    "\n",
    "ext_tw = df_tweets[pd.notna(df_tweets.extended_tweet)].extended_tweet\n",
    "#ext_rtw = df_tweets[pd.notna(df_tweets.reteewted_status)].retweeted_status\n",
    "    \n",
    "#tweets = df_tweets.retweeted_status[2][\"extended_tweet\"]\n",
    "\n",
    "\n",
    "\n",
    "#print(df_tweets.full_text[9:15])\n",
    "df_tweets.head(10)\n",
    "print(df_tweets.extended_tweet[2][\"full_text\"])\n",
    "#print(df_tweets.text[1])\n",
    "print(tweets)\n",
    "print(ext_tw)\n",
    "#print(ext_rtw)\n",
    "df_tweets.retweeted_status[1]\n",
    "df_tweets\n",
    "'''\n",
    "tt = []\n",
    "for i in df_tweets:\n",
    "    if df_tweets.retweeted_status[i] is not None:\n",
    "        x = df_tweets.retweeted_status[i][\"extended_tweet\"][\"full_text\"]\n",
    "        tt.append(x)\n",
    "    else:\n",
    "        pass\n",
    "  '''  \n",
    "print(df_tweets.retweeted_status[1][\"extended_tweet\"][\"full_text\"])\n",
    "print(df_tweets.retweeted_status[1][\"quoted_status\"][\"extended_tweet\"][\"full_text\"])\n",
    "\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'created_at': 'Sun May 13 10:06:44 +0000 2018',\n",
    " 'id': 995606259331207168,\n",
    " 'id_str': '995606259331207168',\n",
    " 'text': 'Ce connard \"Collomb \"avec la complicité des traitre LERM et leur patron le président Macron préfèrent protéger les… https://t.co/OZoXvJqftQ',\n",
    " 'display_text_range': [0, 140],\n",
    " 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
    " 'truncated': True,\n",
    " 'in_reply_to_status_id': None,\n",
    " 'in_reply_to_status_id_str': None,\n",
    " 'in_reply_to_user_id': None,\n",
    " 'in_reply_to_user_id_str': None,\n",
    " 'in_reply_to_screen_name': None,\n",
    " 'user': {'id': 348595451,\n",
    "  'id_str': '348595451',\n",
    "  'name': 'michel',\n",
    "  'screen_name': 'michelM612',\n",
    "  'location': 'France',\n",
    "  'url': None,\n",
    "  'description': \"Patriote et admirateur de Marine.  J'aime la France et je reste attaché a mes racines Gauloises.  Adhérent  FN  , RN  et heureux de l'être.\",\n",
    "  'translator_type': 'none',\n",
    "  'protected': False,\n",
    "  'verified': False,\n",
    "  'followers_count': 1364,\n",
    "  'friends_count': 1686,\n",
    "  'listed_count': 18,\n",
    "  'favourites_count': 1351,\n",
    "  'statuses_count': 16092,\n",
    "  'created_at': 'Thu Aug 04 17:51:29 +0000 2011',\n",
    "  'utc_offset': 7200,\n",
    "  'time_zone': 'Paris',\n",
    "  'geo_enabled': True,\n",
    "  'lang': 'fr',\n",
    "  'contributors_enabled': False,\n",
    "  'is_translator': False,\n",
    "  'profile_background_color': 'ACDED6',\n",
    "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme18/bg.gif',\n",
    "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme18/bg.gif',\n",
    "  'profile_background_tile': False,\n",
    "  'profile_link_color': '038543',\n",
    "  'profile_sidebar_border_color': 'EEEEEE',\n",
    "  'profile_sidebar_fill_color': 'F6F6F6',\n",
    "  'profile_text_color': '333333',\n",
    "  'profile_use_background_image': True,\n",
    "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1479723060/Oiseaux_en_col_re_normal.jpg',\n",
    "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1479723060/Oiseaux_en_col_re_normal.jpg',\n",
    "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/348595451/1384469712',\n",
    "  'default_profile': False,\n",
    "  'default_profile_image': False,\n",
    "  'following': None,\n",
    "  'follow_request_sent': None,\n",
    "  'notifications': None},\n",
    " 'geo': None,\n",
    " 'coordinates': None,\n",
    " 'place': None,\n",
    " 'contributors': None,\n",
    " 'quoted_status_id': 995603866724065285,\n",
    " 'quoted_status_id_str': '995603866724065285',\n",
    " 'quoted_status': {'created_at': 'Sun May 13 09:57:13 +0000 2018',\n",
    "  'id': 995603866724065285,\n",
    "  'id_str': '995603866724065285',\n",
    "  'text': '#Collomb a essayé de dissimuler que le terroriste de l’opéra était musulman et fiché S en annonçant qu’il était rus… https://t.co/WySFVTUwDY',\n",
    "  'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
    "  'truncated': True,\n",
    "  'in_reply_to_status_id': None,\n",
    "  'in_reply_to_status_id_str': None,\n",
    "  'in_reply_to_user_id': None,\n",
    "  'in_reply_to_user_id_str': None,\n",
    "  'in_reply_to_screen_name': None,\n",
    "  'user': {'id': 4277547755,\n",
    "   'id_str': '4277547755',\n",
    "   'name': 'JC',\n",
    "   'screen_name': 'VentDeLiberteFR',\n",
    "   'location': 'France',\n",
    "   'url': None,\n",
    "   'description': '#MacronNEstPasMonPrésident #LREMtraitres #LRtraitres - pro #FN/#DLF depuis toujours, #Patriote #MFGA #Rémigration #StopIslam #E4E',\n",
    "   'translator_type': 'none',\n",
    "   'protected': False,\n",
    "   'verified': False,\n",
    "   'followers_count': 3262,\n",
    "   'friends_count': 4978,\n",
    "   'listed_count': 43,\n",
    "   'favourites_count': 11303,\n",
    "   'statuses_count': 17428,\n",
    "   'created_at': 'Wed Nov 25 19:29:05 +0000 2015',\n",
    "   'utc_offset': 7200,\n",
    "   'time_zone': 'Bern',\n",
    "   'geo_enabled': False,\n",
    "   'lang': 'fr',\n",
    "   'contributors_enabled': False,\n",
    "   'is_translator': False,\n",
    "   'profile_background_color': '000000',\n",
    "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
    "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
    "   'profile_background_tile': False,\n",
    "   'profile_link_color': '94D487',\n",
    "   'profile_sidebar_border_color': '000000',\n",
    "   'profile_sidebar_fill_color': '000000',\n",
    "   'profile_text_color': '000000',\n",
    "   'profile_use_background_image': False,\n",
    "   'profile_image_url': 'http://pbs.twimg.com/profile_images/972006698134073345/Z5rRMwTE_normal.jpg',\n",
    "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/972006698134073345/Z5rRMwTE_normal.jpg',\n",
    "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/4277547755/1497018537',\n",
    "   'default_profile': False,\n",
    "   'default_profile_image': False,\n",
    "   'following': None,\n",
    "   'follow_request_sent': None,\n",
    "   'notifications': None},\n",
    "  'geo': None,\n",
    "  'coordinates': None,\n",
    "  'place': None,\n",
    "  'contributors': None,\n",
    "  'is_quote_status': False,\n",
    "  'extended_tweet': {'full_text': '#Collomb a essayé de dissimuler que le terroriste de l’opéra était musulman et fiché S en annonçant qu’il était russe. #collombdemission #foutagedegueule',\n",
    "   'display_text_range': [0, 153],\n",
    "   'entities': {'hashtags': [{'text': 'Collomb', 'indices': [0, 8]},\n",
    "     {'text': 'collombdemission', 'indices': [119, 136]},\n",
    "     {'text': 'foutagedegueule', 'indices': [137, 153]}],\n",
    "    'urls': [],\n",
    "    'user_mentions': [],\n",
    "    'symbols': []}},\n",
    "  'quote_count': 1,\n",
    "  'reply_count': 0,\n",
    "  'retweet_count': 1,\n",
    "  'favorite_count': 0,\n",
    "  'entities': {'hashtags': [{'text': 'Collomb', 'indices': [0, 8]}],\n",
    "   'urls': [{'url': 'https://t.co/WySFVTUwDY',\n",
    "     'expanded_url': 'https://twitter.com/i/web/status/995603866724065285',\n",
    "     'display_url': 'twitter.com/i/web/status/9…',\n",
    "     'indices': [117, 140]}],\n",
    "   'user_mentions': [],\n",
    "   'symbols': []},\n",
    "  'favorited': False,\n",
    "  'retweeted': False,\n",
    "  'filter_level': 'low',\n",
    "  'lang': 'fr'},\n",
    " 'is_quote_status': True,\n",
    " 'extended_tweet': {'full_text': 'Ce connard \"Collomb \"avec la complicité des traitre LERM et leur patron le président Macron préfèrent protéger les islamistes plutôt que la population qui n\\'à même pas le pouvoir de se défendre sans étre déféré en justice pour acte raciste . https://t.co/hjHSCZLTEz',\n",
    "  'display_text_range': [0, 241],\n",
    "  'entities': {'hashtags': [],\n",
    "   'urls': [{'url': 'https://t.co/hjHSCZLTEz',\n",
    "     'expanded_url': 'https://twitter.com/VentDeLiberteFR/status/995603866724065285',\n",
    "     'display_url': 'twitter.com/VentDeLiberteF…',\n",
    "     'indices': [242, 265]}],\n",
    "   'user_mentions': [],\n",
    "   'symbols': []}},\n",
    " 'quote_count': 0,\n",
    " 'reply_count': 0,\n",
    " 'retweet_count': 2,\n",
    " 'favorite_count': 2,\n",
    " 'entities': {'hashtags': [],\n",
    "  'urls': [{'url': 'https://t.co/OZoXvJqftQ',\n",
    "    'expanded_url': 'https://twitter.com/i/web/status/995606259331207168',\n",
    "    'display_url': 'twitter.com/i/web/status/9…',\n",
    "    'indices': [116, 139]}],\n",
    "  'user_mentions': [],\n",
    "  'symbols': []},\n",
    " 'favorited': False,\n",
    " 'retweeted': False,\n",
    " 'possibly_sensitive': False,\n",
    " 'filter_level': 'low',\n",
    " 'lang': 'fr'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking where are NAs\n",
    "\n",
    "N = len(df_tweets.index)\n",
    "threshold_pc = 50\n",
    "cols = []\n",
    "\n",
    "for c in df_tweets.columns:\n",
    "    na_pc = round(100*pd.isnull(df_tweets[c]).sum()/N,0)\n",
    "    if na_pc>50:\n",
    "        print(na_pc, '% NA in field', c)\n",
    "        cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total NAs = 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 268 entries, 0 to 267\n",
      "Data columns (total 19 columns):\n",
      "created_at          268 non-null datetime64[ns]\n",
      "entities            268 non-null object\n",
      "favorite_count      268 non-null int64\n",
      "favorited           268 non-null bool\n",
      "filter_level        268 non-null object\n",
      "id                  268 non-null int64\n",
      "id_str              268 non-null int64\n",
      "is_quote_status     268 non-null bool\n",
      "lang                268 non-null object\n",
      "quote_count         268 non-null int64\n",
      "reply_count         268 non-null int64\n",
      "retweet_count       268 non-null int64\n",
      "retweeted           268 non-null bool\n",
      "retweeted_status    268 non-null object\n",
      "source              268 non-null object\n",
      "text                268 non-null object\n",
      "timestamp_ms        268 non-null datetime64[ns]\n",
      "truncated           268 non-null bool\n",
      "user                268 non-null object\n",
      "dtypes: bool(4), datetime64[ns](2), int64(6), object(7)\n",
      "memory usage: 34.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# removing NAs\n",
    "\n",
    "df = df_tweets.drop(cols, axis=1)\n",
    "#df.info()\n",
    "df = df.fillna('no retweeted_status')\n",
    "\n",
    "print(\"total NAs =\",sum(pd.isnull(df).sum()))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @VerlaineDJENI: J'ai zéro à l'école, c'est parce que je suis noir, je rate le bus, c'est parce que je suis noir, la banque me refuse un…\n"
     ]
    }
   ],
   "source": [
    "# preparing text to process\n",
    "\n",
    "df['pre_clean_len'] = [len(t) for t in df.text]\n",
    "df.text[df.pre_clean_len>500]\n",
    "print(df.text[57])\n",
    "\n",
    "# we need to clean stuff like &amp, urls etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning function\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import unidecode\n",
    "\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "\n",
    "def tweet_cleaner_updated(text):\n",
    "    text = unidecode.unidecode(text)\n",
    "    text = re.sub(\"aujourd'hui\",\"aujourdhui\", text)\n",
    "    text = re.sub(\"s'il\",\"si il\", text)\n",
    "    text = re.sub(\"s'\",\"se \", text)\n",
    "    text = re.sub(\"n'\",\"ne \", text)\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", lower_case)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Royaliststeff: @apocalypto06 @FrDesouche @nissalabela Allez ds leur cité, là où il y a la crasse. Car il suffit d'emmener une de c peti…\n",
      "rt allez ds leur cite la ou il la crasse car il suffit emmener une de peti\n"
     ]
    }
   ],
   "source": [
    "# testing the cleaning function\n",
    "\n",
    "testing = df.text\n",
    "\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(tweet_cleaner_updated(t))\n",
    "\n",
    "k=78\n",
    "print(df.text[k]) # original text\n",
    "print(test_result[k]) # clean text\n",
    "\n",
    "testing = pd.DataFrame(testing)\n",
    "test_result = pd.DataFrame(test_result)\n",
    "\n",
    "testing.to_csv('tweets_original.csv', sep=',', encoding='utf-8', header = False)\n",
    "test_result.to_csv('tweets_clean.csv', sep=',', encoding='utf-8', header = False)\n",
    "\n",
    "#testing.to_csv('tweets_original.csv')\n",
    "#test_result.to_csv('tweets_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c328158bbf1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparts\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c328158bbf1c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparts\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parts' is not defined"
     ]
    }
   ],
   "source": [
    "# splits the text to be cleaned by batches of size batch_size, in order to divide computation time\n",
    "\n",
    "batch_size = 40\n",
    "step = 10\n",
    "n = len(df.text)-1\n",
    "\n",
    "nums = [k*parts for k in range(n//batch_size+1)]\n",
    "if n%batch_size != 0:\n",
    "    nums.append(n)\n",
    "\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "\n",
    "#clean_tweet_texts = [] # !!! don't forget to comment this line after first iteration\n",
    "iteration = 3\n",
    "\n",
    "for i in range(nums[iteration-1],nums[iteration]):\n",
    "    if( (i+1)%step == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[iteration] ))                                                                    \n",
    "    clean_tweet_texts.append(tweet_cleaner_updated(df['text'][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
