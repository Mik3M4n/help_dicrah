{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       all 3 of my personalities reading my mans text...\n",
       "1       Il y a une classe qui avait sport et les élève...\n",
       "2       Jviens dtema un film sur netflix j’me dis exac...\n",
       "3       Mais c'est supposé nous faire quoi??? On est p...\n",
       "4                    i need jesus https://t.co/UIoieSySD1\n",
       "5       If my mom doing this she getting her number bl...\n",
       "6       when tom holland finally meets ryan reynolds h...\n",
       "7                                 https://t.co/QL1yF1sUoH\n",
       "8       chadwick boseman : an evolution https://t.co/8...\n",
       "9       Vous êtes sûrs de savoir Skinny c’est quoi au ...\n",
       "10      en bas a droite il est pas à l’endroit jv pete...\n",
       "11      Usually, fans are the ones who end up crying a...\n",
       "12      regardez la beauté de cette femme aussi douce ...\n",
       "13      «beurette» c’est surtout un mot dégradant aux ...\n",
       "14      Bienvenue Thomas Tuchel ! 🇩🇪✔️\\n\\n@PSG_inside ...\n",
       "15      Joyeux anniversaire à Marquinhos qui fête aujo...\n",
       "16      La FOX a encore confirmé qu'une saison 6 de #P...\n",
       "17      Les fachos de twitter ils parlent d'islam tout...\n",
       "18      🚨OFFICIEL🚨\\n\\nThomas Tuchel devient le nouvel ...\n",
       "19             Kaoutar meilleure pp personne va rien dire\n",
       "20      Les militants contre le racisme anti-blanc qua...\n",
       "21      Femme voilée:\\n- arrêtés anti-burkini/pas de p...\n",
       "22      PTDRRRRRR la bonne époque https://t.co/LJL87gLRtO\n",
       "23      Mais bien sûr que oui ! Je lui dirais même : A...\n",
       "24      Reviens faire le juste prix stp tu me manques ...\n",
       "25                     qui cala encore l’ecole wsh c fini\n",
       "26      Si vous voyez quelqu’un avec ce type de lunett...\n",
       "27      Les mecs musclés ici on dirait des meufs gecha...\n",
       "28                     bon bisous https://t.co/cq9nnU5yEH\n",
       "29      Qui calcule les poil aux bras même jles ai jms...\n",
       "                              ...                        \n",
       "2198    #Russie .. Près d'un quart des produits sur le...\n",
       "2199    Allemagne: le FMI réclame des investissements ...\n",
       "2200    #UnFilmUnPolitique\\nAutant en emporte le gland...\n",
       "2201    À votre avis, comment ce bracelet sauve des vi...\n",
       "2202    @__GonFreecs En soi il n'a pas tord. Certains ...\n",
       "2203    Peu importe le nombre. Des morts sont des mort...\n",
       "2204    Toujours pour le Yemen : Presque 1 million de ...\n",
       "2205    195 morts par jour en moyenne dans le conflit ...\n",
       "2206    Merci la FRANCE pour tout ce que tu ma apporte...\n",
       "2207    Officiel : Karl Toko Ekambi remporte le Prix M...\n",
       "2208               @VinceQuarter  https://t.co/HAJ5enGBZO\n",
       "2209    Tu n'as donc jamais connu la route arc en ciel...\n",
       "2210    Cette vidéo elle me fume \"Faut respecté le riz...\n",
       "2211    À l’église on prie pour le Ramadan de  nos frè...\n",
       "2212    💥⚡️💣 Quel gros délire ! Quel match de fou ! 😮\\...\n",
       "2213    Sofiane 🇲🇦 a travaillé dur pour mettre sa mère...\n",
       "2214    C'est à ce moment qu\"on a compris que Kakashi ...\n",
       "2215    [#Stat📊] Coutinho vient  d’inscrire son premie...\n",
       "2216    A la base les grands chênes ne sont que des gl...\n",
       "2217    [#USOALLSTARS] La photo souvenir des deux équi...\n",
       "2218                       🇪🇬🇪🇬🇪🇬 https://t.co/KYOs14wMTG\n",
       "2219    #Gaza dans l’indifférence générale , le degré ...\n",
       "2220    Agression à #Paris : je salue le sang froid et...\n",
       "2221    @MarieVisot C'est 1 bonne chose si l'#UE 🇪🇺 co...\n",
       "2222    Le pétrolier et gazier chinois CNPC envisage d...\n",
       "2223    Today, Donald Trump simultaneously lied about ...\n",
       "2224    Netanyahu en 2002..  \"Si vous virez Saddam, il...\n",
       "2225    🇮🇷🇮🇷🇮🇷 Ce que je vois depuis 10 jours en #Iran...\n",
       "2226    Le drapeau américain a été brûlé au sein du Pa...\n",
       "2227    🗨️ @BrunoRetailleau \"L'Europe, avec l'Angleter...\n",
       "Length: 2228, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 14 11:56:35 2018\n",
    "\n",
    "@author: Eduard\n",
    "\n",
    "Ce script sert à parser les messages texte des 20 Tweets aléatoires (+commentaires)\n",
    "ayant été scrapés du compte de chaque usager dont nous avons détecté un message \n",
    "incorporant l'un de nos termes cible. Ils n'incorporent pas forcément l'un des \n",
    "mots-cibles, mais sont écrits par les mêmes usagers (introduction d'un dégré aléatoire).\n",
    "Ils sont tous concatennés dans un fichier CSV pour lecture aisée sur Excel et \n",
    "labélisation manuelle.\n",
    "\n",
    "\"\"\"\n",
    "import json, glob, os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# On indique le chemin vers les fichiers JSON de Tweets scrappés\n",
    "path = os.getcwd()+'/StreamListenerTweepy/Users/*.jsonl'\n",
    "\n",
    "\n",
    "# On crée deux fonctions pour itérer le parse sur plusieurs fichiers JSON \n",
    "# placés sur le même dossier\n",
    "def read_json_files(path_to_file):\n",
    "    with open(path_to_file) as p:\n",
    "        data = pd.read_json(p, lines=True)\n",
    "    return data\n",
    "\n",
    "def giant_list(json_files):\n",
    "    data_list = []\n",
    "    for f in json_files:\n",
    "        data_list.append(read_json_files(f))\n",
    "    return data_list\n",
    "\n",
    "\n",
    "# Éxecution de fonctions et chargement de JSON dans un DF concatenné\n",
    "event_files = glob.glob(path)\n",
    "tweets = pd.concat(giant_list(event_files), ignore_index=True)\n",
    "tweets = tweets[[\"retweeted_status\"]]\n",
    "\n",
    "\n",
    "# Extraction des index des lignes non vides et à parser\n",
    "index_ret = tweets.retweeted_status[tweets.retweeted_status.notnull()].index\n",
    "\n",
    "\n",
    "# Si le stream a un champ \"extended_tweet\" on récupère les index des ces tweets\n",
    "# pour effectuer ensuite une boucle d'extraction du texte en entier.\n",
    "j=[]\n",
    "for i in index_ret:\n",
    "    if \"full_text\" in tweets.retweeted_status[i]:\n",
    "        j.append(i)\n",
    "        \n",
    "for i in j:\n",
    "    tweets.retweeted_status[i] = tweets.retweeted_status[i][\"full_text\"]\n",
    "\n",
    "    \n",
    "# Enfin, on fusionne tous les tweets qui doivent être labelisées manuellement et on efface les dupliqués\n",
    "tweets_dilcrah_users = tweets.stack().dropna().drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# À cette fin, on exporte en csv pour pouvoir faire la lecture et labélisation sur Excel\n",
    "tweets_dilcrah_users.to_csv('TweetsToLabelCSV/tweets_dilcrah_users.csv', sep=',', encoding='utf-8', header = False)\n",
    "\n",
    "\n",
    "tweets_dilcrah_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
